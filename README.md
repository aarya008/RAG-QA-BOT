# ğŸ§  RAGChat Bot â€” PDF Question Answering using LangChain, Gemini & Gradio

### ğŸš€ An intelligent chatbot that reads your documents, understands your questions, and gives precise answers â€” powered by **Retrieval-Augmented Generation (RAG)** with **LangChain**, **Google Gemini**, and **HuggingFace Embeddings**.


## ğŸ—‚ï¸ Project Overview

This project implements a **RAG-based chatbot** capable of answering user queries from uploaded **PDF documents**.
It combines **Large Language Models (LLMs)** with a **Vector Database (Chroma)** to retrieve and reason over document content, making it an efficient and scalable **Document Q&A System**.

**Tech Stack Used:**

* ğŸ§© **LangChain** â€” RAG pipeline & data orchestration
* ğŸª¶ **Google Gemini (Generative AI)** â€” LLM for reasoning and answering
* ğŸ¤— **HuggingFace Sentence Transformers** â€” for high-quality text embeddings
* ğŸ§± **ChromaDB** â€” vector store for semantic search and retrieval
* âš™ï¸ **Gradio** â€” frontend UI for chatbot interaction
* ğŸ **Python** (with PyTorch) â€” core programming and model integration

## âœ¨ Features

âœ… Upload any **PDF file** up to 100 MB
âœ… Automatically extracts and splits text into chunks
âœ… Generates **semantic embeddings** using HuggingFace
âœ… Stores document knowledge in a **persistent vector database**
âœ… Retrieves contextually relevant information using **Chroma retriever**
âœ… Provides accurate and **LLM-powered answers** using Google Gemini
âœ… Clean and modern **Gradio chatbot interface**
âœ… Built with scalability and GPU support (CUDA/MPS detection)


## ğŸ§© Project Architecture

flowchart TD
A[PDF Upload] --> B[Document Loader (LangChain)]
B --> C[Text Splitter]
C --> D[HuggingFace Embeddings]
D --> E[Chroma Vector DB (Persistent)]
E --> F[Retriever]
F --> G[Google Gemini LLM]
G --> H[Gradio Frontend Chatbot]
H --> I[User Interaction]
```

---

## ğŸ’¡ Core Functionalities

| Function                | Description                                      |
| ----------------------- | ------------------------------------------------ |
| `upload_file()`         | Handles PDF uploads and vector DB persistence    |
| `vector_database()`     | Builds or loads existing embeddings for a file   |
| `retriever_qa()`        | Core RAG logic for contextual question-answering |
| `get_llm()`             | Initializes Google Gemini (Gemini 2.5 Flash)     |
| `get_embedding_model()` | Uses sentence-transformers/all-mpnet-base-v2     |
| `gradio_qa()`           | Connects Gradio frontend to backend logic        |


## ğŸ§  Skills Demonstrated

* Retrieval-Augmented Generation (RAG)
* LangChain workflow engineering
* LLM integration (Google Gemini)
* Vector Databases (Chroma)
* Natural Language Processing (NLP)
* PDF text extraction and document parsing
* UI development with Gradio
* GPU-aware model optimization (PyTorch)

## ğŸ§¾ Example Usage

1. Upload your PDF (research paper, report, documentation, etc.)
2. Ask: *â€œSummarize chapter 2 in simple terms.â€*
3. The chatbot retrieves relevant content and gives a **concise, contextual, and AI-generated answer**.


## âš–ï¸ License

This project is licensed under the **MIT License** â€” youâ€™re free to use and modify it with attribution.
(You can switch to Apache-2.0 if you want stronger protection for derivative works.)

## ğŸ‘¨â€ğŸ’» Author

**Aarya Tagare**
ğŸ“ Electrical Engineer | ğŸ’¡ AI & Cybersecurity Enthusiast | âš™ï¸ Embedded Systems Developer
ğŸ“ Kolhapur, India
ğŸ”— [LinkedIn](https://www.linkedin.com) â€¢ [GitHub](https://github.com/your-username) â€¢ [Email](mailto:your-email@example.com)

